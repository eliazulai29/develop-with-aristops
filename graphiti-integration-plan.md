# Graphiti + BAML Integration Plan for DeepWiki
## Enhancing Multi-Interface Repository Intelligence

---

## ğŸ¯ **Executive Summary**

Enhance DeepWiki's existing **AdalFlow + FAISS architecture** with **BAML classification** and **Graphiti knowledge graphs** to enable intelligent cross-repository analysis while preserving all current functionality.

**Goal**: Transform "how to build" queries from simple code search to structured architectural guidance across multiple repositories and interfaces.

---

## ğŸ—ï¸ **Current System Architecture Analysis**

### **Discovered Multi-Interface System**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CURRENT DEEPWIKI SYSTEM                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Client Interfaces:                                             â”‚
â”‚  â”œâ”€â”€ ğŸŒ Web UI (Next.js) - Interactive chat & wiki generation  â”‚
â”‚  â”œâ”€â”€ ğŸ”Œ WebSocket (/ws/chat) - External agents (coding-agent)   â”‚
â”‚  â”œâ”€â”€ ğŸ”— HTTP API (/chat/completions/stream) - API integration   â”‚
â”‚  â””â”€â”€ ğŸ“¤ Export API (/export/wiki) - Data consumption           â”‚
â”‚                                                                 â”‚
â”‚  Backend (FastAPI + AdalFlow):                                  â”‚
â”‚  â”œâ”€â”€ ğŸ§  RAG Pipeline - FAISS retrieval (637 docs indexed)      â”‚
â”‚  â”œâ”€â”€ ğŸ” Deep Research - Multi-iteration [DEEP RESEARCH] mode   â”‚
â”‚  â”œâ”€â”€ ğŸ’¾ Multi-layer Caching - Repos, embeddings, wiki cache   â”‚
â”‚  â”œâ”€â”€ ğŸŒ Multi-Provider LLMs - 6 providers, 9 languages        â”‚
â”‚  â””â”€â”€ ğŸ” Private Repo Support - GitHub tokens, file filtering   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Current Strengths**
- âœ… **Mature AdalFlow integration** with proven RAG pipeline
- âœ… **Multi-interface architecture** supporting diverse clients
- âœ… **Advanced caching strategy** for performance optimization
- âœ… **Deep research capabilities** with iterative refinement
- âœ… **External agent integration** via WebSocket interface
- âœ… **Production-ready streaming** with completion signaling

### **Enhancement Opportunities**
- ğŸ¯ **Query Understanding**: No intent classification or entity extraction
- ğŸ—ï¸ **Cross-Repository Analysis**: Each repo processed in isolation
- ğŸ“Š **Structured Responses**: Free-form text vs. actionable guidance
- ğŸ”— **Relationship Mapping**: No architectural dependency understanding

---

## ğŸš€ **Enhanced Architecture Design**

### **Integration Strategy: Enhance, Don't Replace**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ENHANCED DEEPWIKI SYSTEM                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¯ BAML Intelligence Layer (NEW)                                   â”‚
â”‚  â”œâ”€â”€ Query Classification â†’ Intent, Complexity, Scope              â”‚
â”‚  â”œâ”€â”€ Entity Extraction â†’ Technologies, Components, Patterns        â”‚
â”‚  â”œâ”€â”€ Response Structuring â†’ Step-by-step guides, Confidence        â”‚
â”‚  â””â”€â”€ Research Planning â†’ Smart iteration strategies                â”‚
â”‚                                                                     â”‚
â”‚  ğŸ•¸ï¸ Graphiti Knowledge Layer (NEW)                                  â”‚
â”‚  â”œâ”€â”€ Cross-Repository Relationships â†’ Dependencies, Similarities   â”‚
â”‚  â”œâ”€â”€ Component Architecture Mapping â†’ Class â†’ Function â†’ Module    â”‚
â”‚  â”œâ”€â”€ Technology Stack Analysis â†’ Framework usage patterns          â”‚
â”‚  â””â”€â”€ Build Pattern Recognition â†’ How components connect             â”‚
â”‚                                                                     â”‚
â”‚  ğŸ§  Enhanced AdalFlow Pipeline (ENHANCED)                           â”‚
â”‚  â”œâ”€â”€ Smart Query Routing â†’ BAML classification determines strategy â”‚
â”‚  â”œâ”€â”€ Hybrid Retrieval â†’ FAISS + Graphiti based on query type      â”‚
â”‚  â”œâ”€â”€ Intelligent Deep Research â†’ BAML-guided iteration planning    â”‚
â”‚  â””â”€â”€ Structured Response Generation â†’ Type-safe, actionable output â”‚
â”‚                                                                     â”‚
â”‚  ğŸ’¾ Enhanced Caching Strategy (ENHANCED)                            â”‚
â”‚  â”œâ”€â”€ Existing Caches â†’ Repos, embeddings, wiki (preserved)        â”‚
â”‚  â”œâ”€â”€ BAML Classification Cache â†’ Cache common query patterns       â”‚
â”‚  â”œâ”€â”€ Graphiti Relationship Cache â†’ Pre-computed graph connections  â”‚
â”‚  â””â”€â”€ Structured Response Cache â†’ Reuse architectural guidance      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 UNCHANGED INTERFACE LAYER                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸŒ Web UI        â”‚  ğŸ”Œ WebSocket      â”‚  ğŸ”— HTTP API  â”‚  ğŸ“¤ Export  â”‚
â”‚  Enhanced with    â”‚  Structured output â”‚  Fallback     â”‚  Enhanced   â”‚
â”‚  intent detection â”‚  for external      â”‚  compatibilityâ”‚  with graph â”‚
â”‚  and suggestions  â”‚  agents            â”‚  maintained   â”‚  relationshipsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š **Knowledge Graph Schema**

### **Node Types**
```yaml
Repository:
  properties:
    - name: string
    - owner: string  
    - language: string
    - size: integer
    - last_updated: datetime
    - tech_stack: array

Component:
  properties:
    - name: string
    - type: enum [class, function, module, service]
    - file_path: string
    - responsibility: string
    - complexity: integer

Technology:
  properties:
    - name: string
    - category: enum [framework, library, tool, language]
    - version: string

Pattern:
  properties:
    - name: string
    - type: enum [design_pattern, architecture_pattern]
    - description: string
```

### **Relationship Types**
```yaml
DEPENDS_ON:
  - Repository -> Repository
  - Component -> Component
  - Repository -> Technology

IMPLEMENTS:
  - Component -> Pattern
  - Repository -> Pattern

CONTAINS:
  - Repository -> Component
  - Component -> Component

SIMILAR_TO:
  - Component -> Component
  - Repository -> Repository

EVOLVED_FROM:
  - Repository -> Repository
  - Component -> Component
```

---

## ğŸ”§ **BAML Schema Design**

### **Core Classification Schema**
```typescript
// baml/classification.baml
enum QueryIntent {
  BUILD_GUIDANCE        // "How do I build X?" 
  DEBUGGING_HELP        // "What's the root cause of this error?"
  ARCHITECTURE_ANALYSIS // "How does this system work?"
  CODE_SEARCH          // "Find examples of X"
  DEEP_RESEARCH        // Enhanced [DEEP RESEARCH] planning
}

enum QueryScope {
  SINGLE_REPO    // Query about one repository
  CROSS_REPO     // Compare/combine multiple repositories  
  SYSTEM_WIDE    // Ecosystem-level questions
}

class QueryClassification {
  intent: QueryIntent
  scope: QueryScope
  complexity: "SIMPLE" | "INTERMEDIATE" | "ADVANCED"
  technologies: string[]
  enhanced_query: string
  confidence: float
}
```

### **Response Structuring Schema**
```typescript
// baml/responses.baml
class BuildStep {
  step_number: int
  title: string
  description: string
  code_examples: CodeExample[]
  dependencies: string[]
  next_steps: string[]
}

class CodeExample {
  repository: string
  file_path: string
  content: string
  explanation: string
  language: string
}

class StructuredResponse {
  intent: QueryIntent
  summary: string
  build_steps: BuildStep[]           // For BUILD_GUIDANCE
  architecture_overview: string     // For ARCHITECTURE_ANALYSIS  
  troubleshooting_steps: string[]   // For DEBUGGING_HELP
  related_repositories: string[]
  confidence_score: float
}
```

### **Repository Relationship Schema**
```typescript
// baml/relationships.baml
enum RelationshipType {
  SIMILAR_ARCHITECTURE    // Similar patterns/structure
  COMPLEMENTARY_TECH     // Different tech, same goal
  DEPENDENCY            // One depends on the other
  EVOLUTION            // One evolved from the other
}

class RepositoryRelationship {
  source_repo: string
  target_repo: string
  relationship_type: RelationshipType
  explanation: string
  strength: float
}
```

---

## âš¡ **AdalFlow Integration Strategy**

### **Enhancing Existing RAG Pipeline**
```python
# api/enhanced_rag.py - Extends existing api/rag.py
from api.rag import RAG  # Existing RAG class
from baml_client import b  # Generated BAML client
from adalflow import Generator

class EnhancedRAG(RAG):  # Inherit from existing RAG
    def __init__(self, provider="openai", model=None):
        super().__init__(provider, model)  # Initialize existing RAG
        
        # Add BAML classification to existing pipeline
        self.query_classifier = Generator(
            model_client=self.generator.model_client,  # Reuse existing client
            template=b.ClassifyQuery,
            output_processors=[b.QueryClassification]
        )
        
        # Add response structuring
        self.response_structurer = Generator(
            model_client=self.generator.model_client,
            template=b.StructureResponse,
            output_processors=[b.StructuredResponse]
        )

    async def enhanced_call(self, query: str, language: str = "en"):
        # Step 1: Classify query with BAML
        classification = await self.query_classifier(
            query=query,
            conversation_history=self.memory(),
            repository_context=self.repo_url_or_path
        )
        
        # Step 2: Route based on classification
        if classification.scope == "CROSS_REPO":
            # Use Graphiti for cross-repo analysis
            documents = await self.graphiti_enhanced_retrieval(classification)
        else:
            # Use existing FAISS pipeline (unchanged)
            documents = self(classification.enhanced_query, language)
        
        # Step 3: Structure response with BAML
        structured_response = await self.response_structurer(
            query=query,
            classification=classification,
            retrieved_documents=documents
        )
        
        return structured_response
```

### **WebSocket Integration: Minimal Changes**
```python
# api/websocket_wiki.py - Minimal changes to existing file
async def handle_websocket_chat(websocket: WebSocket):
    # ... existing setup code unchanged ...
    
    # Replace existing RAG with EnhancedRAG
    request_rag = EnhancedRAG(provider=request.provider, model=request.model)
    request_rag.prepare_retriever(...)  # Existing method unchanged
    
    # ... existing Deep Research detection unchanged ...
    
    # Enhanced query processing
    if should_use_enhanced_features(query):
        structured_response = await request_rag.enhanced_call(query, language)
        await stream_structured_response(websocket, structured_response)
    else:
        # Fall back to existing pipeline (zero breaking changes)
        retrieved_documents = request_rag(query, language)
        # ... existing streaming code unchanged ...
```

### **Backward Compatibility Guarantee**
- **âœ… Zero Breaking Changes**: All existing functionality preserved
- **âœ… Gradual Enhancement**: New features opt-in, existing features unchanged
- **âœ… Interface Preservation**: All APIs (WebSocket, HTTP, Export) work as before
- **âœ… Configuration Compatibility**: All existing model providers and settings work
- **âœ… Fallback Strategy**: If BAML/Graphiti fails, fall back to existing FAISS pipeline

---

## ğŸ”„ **Repository Onboarding Process**

### **Phase 1: FAISS Processing (Existing)**
```
1. Clone Repository
2. Extract Code Files
3. Generate Embeddings  
4. Build FAISS Index
5. Cache Results
```

### **Phase 2: Graphiti Analysis (New)**
```
1. Code Structure Analysis
   â”œâ”€â”€ Parse AST for classes, functions, imports
   â”œâ”€â”€ Identify design patterns
   â”œâ”€â”€ Extract dependencies
   â””â”€â”€ Map file relationships

2. Technology Stack Detection
   â”œâ”€â”€ Parse package.json, requirements.txt, etc.
   â”œâ”€â”€ Identify frameworks and libraries
   â”œâ”€â”€ Detect architectural patterns
   â””â”€â”€ Version analysis

3. Cross-Repository Matching
   â”œâ”€â”€ Compare technology stacks
   â”œâ”€â”€ Find similar components
   â”œâ”€â”€ Identify potential dependencies
   â””â”€â”€ Detect code patterns

4. Knowledge Graph Update
   â”œâ”€â”€ Create/update repository node
   â”œâ”€â”€ Add component nodes
   â”œâ”€â”€ Establish relationships
   â””â”€â”€ Update similarity scores
```

---

## ğŸ¯ **Enhanced Query Processing Flow**

### **Smart Pipeline: From Query to Structured Response**
```
Example: External Agent Query â†’ "How do I build a Docker-based coding agent?"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. BAML Classification (NEW)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Intent: BUILD_GUIDANCE | Complexity: INTERMEDIATE                   â”‚
â”‚ Scope: CROSS_REPO | Technologies: ["Docker", "Agent", "Python"]    â”‚
â”‚ Enhanced Query: "Docker containerization patterns for agent systems"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Smart Routing Decision (NEW)                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Query Type: CROSS_REPO â†’ Use Graphiti + FAISS                      â”‚
â”‚ If SINGLE_REPO â†’ Use existing FAISS pipeline                       â”‚
â”‚ If DEBUGGING â†’ Use enhanced FAISS with error patterns              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Hybrid Information Retrieval (ENHANCED)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FAISS: Find Docker + Agent code examples (existing)                â”‚
â”‚ Graphiti: Map relationships between coding-agent â†’ hekmatica       â”‚
â”‚ Result: coding-agent (Docker patterns) + hekmatica (API patterns)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. BAML Response Structuring (NEW)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Format: STEP_BY_STEP_GUIDE with cross-repository examples          â”‚
â”‚ Include: Dependencies, code examples, next steps, confidence        â”‚
â”‚ Output: Type-safe structured response for WebSocket streaming       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Example Enhanced Responses**

**Before (FAISS Only):**
```
Q: "How do I build a Docker-based coding agent?"
A: Here's some Docker code from coding-agent repository...
   [Shows isolated code snippets]
```

**After (FAISS + Graphiti + BAML):**
```
Q: "How do I build a Docker-based coding agent?"

ğŸ¤– BAML Classification:
- Intent: BUILD_GUIDANCE
- Complexity: INTERMEDIATE  
- Scope: CROSS_REPO
- Technologies: ["Docker", "Agent", "Python", "FastAPI"]

A: Based on your repositories, here's the complete structured architecture:

ğŸ—ï¸ Architecture Overview:
- coding-agent implements: Agent Core + Docker Manager  
- hekmatica provides: Backend API patterns
- develop-with-aristops shows: Integration examples

ğŸ”„ Step-by-Step Build Guide:

Step 1: Core Agent Setup
â”œâ”€â”€ File: coding-agent/src/core/agent.py
â”œâ”€â”€ Dependencies: ["AdalFlow", "TaskHandler", "StateManager"]
â”œâ”€â”€ Code Example: [Type-safe code snippet with explanations]
â””â”€â”€ Next Steps: ["Setup Docker Manager", "Configure State Management"]

Step 2: Docker Environment Manager  
â”œâ”€â”€ File: coding-agent/src/sandbox/docker_manager.py
â”œâ”€â”€ Dependencies: ["Docker API", "Volume Management"]
â”œâ”€â”€ Code Example: [Container lifecycle management]
â””â”€â”€ Next Steps: ["API Integration", "Error Handling"]

Step 3: API Integration (from hekmatica patterns)
â”œâ”€â”€ Pattern: FastAPI + WebSocket streaming
â”œâ”€â”€ Code Example: [WebSocket implementation with completion signals]
â””â”€â”€ Next Steps: ["Frontend Integration"]

Step 4: Frontend Interface (from develop-with-aristops patterns)
â”œâ”€â”€ Pattern: Next.js + TypeScript integration
â”œâ”€â”€ Code Example: [Agent interaction UI components]
â””â”€â”€ Next Steps: ["Testing", "Deployment"]

ğŸ”— Cross-Repository Dependencies:
- Docker API â†’ Agent Core â†’ Task Handler â†’ State Manager
- FastAPI (hekmatica) â†’ WebSocket (your current wiki)
- Frontend patterns â†’ Chat interface

ğŸ“Š Confidence Score: 92% (High confidence based on code analysis)
ğŸ”— Related Repositories: [coding-agent, hekmatica, develop-with-aristops]
ğŸ“š Additional Resources: [Docker best practices, AdalFlow documentation]
```

---

## ğŸš€ **Implementation Roadmap**

### **Phase 1: BAML Foundation (Week 1)**
```
Goal: Add query classification without breaking existing functionality

1. BAML Setup
   â”œâ”€â”€ Install BAML CLI and dependencies in api/
   â”œâ”€â”€ Create baml_src/ directory with core schemas
   â”œâ”€â”€ Generate TypeScript/Python clients
   â””â”€â”€ Test basic classification with existing queries

2. Enhanced RAG Creation
   â”œâ”€â”€ Create api/enhanced_rag.py extending existing RAG
   â”œâ”€â”€ Add BAML classification to query processing
   â”œâ”€â”€ Implement fallback to existing pipeline
   â””â”€â”€ Test with WebSocket interface

3. Validation
   â”œâ”€â”€ Verify all existing functionality works unchanged
   â”œâ”€â”€ Test enhanced features with simple queries
   â”œâ”€â”€ Monitor performance impact (should be minimal)
   â””â”€â”€ Document new capabilities
```

### **Phase 2: Cross-Repository Intelligence (Week 2-3)**
```
Goal: Enable basic cross-repository understanding

1. Graphiti Integration
   â”œâ”€â”€ Install Graphiti dependencies
   â”œâ”€â”€ Choose database backend (FalkorDB for simplicity)
   â”œâ”€â”€ Create repository relationship schemas
   â””â”€â”€ Build basic cross-repo analysis

2. Repository Analysis Enhancement
   â”œâ”€â”€ Extend existing data_pipeline.py with graph analysis
   â”œâ”€â”€ Add relationship detection during repo processing
   â”œâ”€â”€ Create repository similarity scoring
   â””â”€â”€ Update caching to include relationship data

3. Enhanced Search Implementation
   â”œâ”€â”€ Create hybrid FAISS + Graphiti search
   â”œâ”€â”€ Route queries based on BAML classification
   â”œâ”€â”€ Test with coding-agent â†” hekmatica relationships
   â””â”€â”€ Validate performance meets <3s target
```

### **Phase 3: Production Optimization (Week 4)**
```
Goal: Optimize for production use with external agents

1. Performance Optimization
   â”œâ”€â”€ Cache BAML classifications for common patterns
   â”œâ”€â”€ Pre-compute repository relationships
   â”œâ”€â”€ Optimize graph queries for speed
   â””â”€â”€ Add monitoring and metrics

2. External Agent Enhancement
   â”œâ”€â”€ Optimize WebSocket structured responses
   â”œâ”€â”€ Add export API relationship data
   â”œâ”€â”€ Test with your coding-agent integration
   â””â”€â”€ Document new API capabilities

3. Production Readiness
   â”œâ”€â”€ Add comprehensive error handling
   â”œâ”€â”€ Create migration scripts for existing data
   â”œâ”€â”€ Update documentation and examples
   â””â”€â”€ Deploy and monitor in production
```

---

## ğŸ“ **File Structure Changes**

### **New Files to Create**
```
baml_src/                      # BAML schema definitions (Phase 1)
â”œâ”€â”€ classification.baml        # Query intent and scope classification
â”œâ”€â”€ responses.baml            # Structured response formatting
â”œâ”€â”€ relationships.baml        # Repository relationship modeling
â””â”€â”€ baml_client/              # Generated BAML client code

api/
â”œâ”€â”€ enhanced_rag.py           # Extended RAG with BAML (Phase 1)
â”œâ”€â”€ graphiti_integration.py   # Graphiti knowledge graph (Phase 2)
â”œâ”€â”€ repository_analyzer.py    # Cross-repo analysis (Phase 2)
â””â”€â”€ config/
    â””â”€â”€ graphiti.json         # Graph database configuration (Phase 2)
```

### **Files to Modify**
```
api/
â”œâ”€â”€ websocket_wiki.py         # Replace RAG with EnhancedRAG (Phase 1)
â”œâ”€â”€ data_pipeline.py          # Add relationship analysis (Phase 2)
â”œâ”€â”€ requirements.txt          # Add BAML and Graphiti dependencies
â””â”€â”€ api.py                    # Add relationship endpoints (Phase 2)

Optional UI Enhancements (Phase 3):
src/components/Ask.tsx         # Enhanced with intent detection
```

### **Files That Remain Unchanged**
```
âœ… All existing configuration files (api/config/*.json)
âœ… All existing caching mechanisms (api/api.py cache functions)
âœ… All existing model clients (api/*_client.py)
âœ… All existing UI components (except optional Ask.tsx enhancement)
âœ… All existing interfaces (WebSocket, HTTP, Export APIs)
```

---

## ğŸ¯ **Success Metrics**

### **Technical Metrics**
- **Query Response Quality**: 90% relevant cross-repo answers
- **Performance**: <3s for hybrid queries
- **Graph Coverage**: 95% of components mapped
- **Relationship Accuracy**: 85% correct dependencies

### **User Experience Metrics**
- **Build Guide Completeness**: 90% actionable steps
- **Cross-Repository Discovery**: 70% find related repos
- **Architecture Understanding**: 80% comprehend dependencies
- **Developer Productivity**: 40% faster project setup

---

## âš ï¸ **Challenges & Mitigations**

### **Technical Challenges**
```
1. Performance Impact
   Challenge: Graph queries may be slower than FAISS
   Mitigation: 
   - Intelligent query routing
   - Graph query optimization
   - Caching strategies
   - Parallel processing

2. Data Consistency
   Challenge: Keeping graph and vector data in sync
   Mitigation:
   - Unified update pipeline
   - Version tracking
   - Rollback capabilities
   - Health monitoring

3. Schema Evolution
   Challenge: Changing graph schema as system grows
   Mitigation:
   - Migration scripts
   - Backward compatibility
   - Gradual updates
   - Schema versioning
```

### **Business Challenges**
```
1. Infrastructure Costs
   Challenge: Additional database and processing costs
   Mitigation:
   - Start with lightweight FalkorDB
   - Optimize for essential relationships
   - Gradual scaling approach

2. Complexity Management
   Challenge: System becomes more complex
   Mitigation:
   - Comprehensive testing
   - Clear documentation
   - Monitoring and alerts
   - Fallback to FAISS-only mode
```

---

## ğŸ”„ **Enhanced Repository Refresh Flow**

### **Current Refresh System Analysis**
Your system has a sophisticated **multi-layer caching architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CURRENT REFRESH WORKFLOW                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Frontend triggers "Refresh Wiki" button                         â”‚
â”‚ 2. DELETE /api/wiki_cache â†’ Clears wiki structure cache            â”‚
â”‚ 3. LocalDB.save_state() â†’ Preserves FAISS index unless deleted     â”‚
â”‚ 4. Repository reprocessing â†’ Creates new embeddings if needed      â”‚
â”‚ 5. New wiki generation â†’ Fresh content with existing or new index  â”‚
â”‚                                                                     â”‚
â”‚ Cache Locations:                                                    â”‚
â”‚ â”œâ”€â”€ ~/.adalflow/repos/ â†’ Cloned repository files                   â”‚
â”‚ â”œâ”€â”€ ~/.adalflow/databases/ â†’ FAISS embeddings (owner_repo.pkl)     â”‚
â”‚ â””â”€â”€ ~/.adalflow/wikicache/ â†’ Generated wiki content               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Enhanced Refresh Flow with BAML + Graphiti**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ENHANCED REFRESH WORKFLOW                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Frontend: "Refresh Wiki" â†’ Enhanced with intelligence options   â”‚
â”‚                                                                     â”‚
â”‚ 2. Cache Invalidation (Enhanced):                                  â”‚
â”‚    â”œâ”€â”€ DELETE /api/wiki_cache â†’ Wiki structure (unchanged)         â”‚
â”‚    â”œâ”€â”€ Clear BAML classification cache â†’ Force intent re-analysis  â”‚
â”‚    â”œâ”€â”€ Clear Graphiti relationships â†’ Rebuild cross-repo analysis  â”‚
â”‚    â””â”€â”€ Optional: Clear FAISS embeddings â†’ Force full reindex      â”‚
â”‚                                                                     â”‚
â”‚ 3. Repository Reprocessing (Enhanced):                             â”‚
â”‚    â”œâ”€â”€ Standard: File analysis â†’ FAISS embeddings                 â”‚
â”‚    â”œâ”€â”€ NEW: BAML Repository Analysis â†’ Extract technologies/patternsâ”‚
â”‚    â””â”€â”€ NEW: Graphiti Relationship Mapping â†’ Cross-repo connections â”‚
â”‚                                                                     â”‚
â”‚ 4. Incremental vs Full Refresh:                                    â”‚
â”‚    â”œâ”€â”€ Smart Refresh: Only reprocess changed relationships         â”‚
â”‚    â”œâ”€â”€ Full Refresh: Complete FAISS + Graphiti rebuild             â”‚
â”‚    â””â”€â”€ Force Refresh: Clear all caches, rebuild everything         â”‚
â”‚                                                                     â”‚
â”‚ 5. Enhanced Cache Structure:                                       â”‚
â”‚    â”œâ”€â”€ ~/.adalflow/repos/ â†’ Repository files (unchanged)           â”‚
â”‚    â”œâ”€â”€ ~/.adalflow/databases/ â†’ FAISS embeddings (unchanged)       â”‚
â”‚    â”œâ”€â”€ ~/.adalflow/graphiti/ â†’ Repository relationships (NEW)      â”‚
â”‚    â”œâ”€â”€ ~/.adalflow/baml_cache/ â†’ Classification patterns (NEW)     â”‚
â”‚    â””â”€â”€ ~/.adalflow/wikicache/ â†’ Wiki content (enhanced metadata)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **New Refresh Options for Users**
```typescript
interface RefreshOptions {
  refreshType: "smart" | "full" | "force";
  rebuildRelationships: boolean;
  clearClassificationCache: boolean;
  reanalyzeRepositoryStructure: boolean;
}

// Smart Refresh (Default) - Only rebuild changed components
// Full Refresh - Rebuild FAISS + Graphiti, keep classification cache
// Force Refresh - Clear everything, complete rebuild
```

### **Enhanced DatabaseManager Implementation**
```python
# api/enhanced_database_manager.py
class EnhancedDatabaseManager(DatabaseManager):
    def __init__(self):
        super().__init__()
        self.graphiti_client = None
        self.baml_cache = {}
        
    def prepare_database(self, repo_url_or_path: str, refresh_options: dict = None):
        """Enhanced database preparation with BAML + Graphiti support"""
        
        # 1. Standard FAISS processing (existing)
        if refresh_options.get("rebuild_faiss", False):
            # Force rebuild FAISS embeddings
            self.clear_faiss_cache()
        documents = super().prepare_database(repo_url_or_path)
        
        # 2. BAML Repository Analysis (NEW)
        if refresh_options.get("reanalyze_structure", True):
            repo_analysis = self.analyze_repository_with_baml(documents)
            self.cache_repository_analysis(repo_analysis)
        
        # 3. Graphiti Relationship Processing (NEW)
        if refresh_options.get("rebuild_relationships", True):
            self.update_graphiti_relationships(repo_url_or_path, repo_analysis)
        
        return documents
    
    def analyze_repository_with_baml(self, documents):
        """Extract repository patterns and technologies using BAML"""
        # Use BAML to classify repository type, tech stack, patterns
        return baml_repository_analyzer(documents)
    
    def update_graphiti_relationships(self, repo_url, analysis):
        """Update cross-repository relationships in Graphiti"""
        # Find similar repositories and map dependencies
        self.graphiti_client.add_repository_node(repo_url, analysis)
        self.graphiti_client.map_relationships(repo_url, analysis)
```

### **Real-World Refresh Scenarios**

#### **Scenario 1: Your coding-agent gets updated**
```
User: Refreshes coding-agent repository
Enhanced System:
1. âœ… Clears wiki cache (existing behavior)
2. ğŸ†• BAML detects new Docker patterns, AdalFlow integration
3. ğŸ†• Graphiti updates relationships with hekmatica (backend patterns)
4. ğŸ†• Future queries get enhanced cross-repo guidance
```

#### **Scenario 2: Adding a new repository**
```
User: Processes new repository "deployment-scripts"
Enhanced System:
1. âœ… Creates FAISS embeddings (existing)
2. ğŸ†• BAML classifies as "INFRASTRUCTURE" with Docker/K8s patterns
3. ğŸ†• Graphiti maps relationships: deployment-scripts â†’ coding-agent â†’ hekmatica
4. ğŸ†• Cross-repo queries now include deployment guidance
```

#### **Scenario 3: Smart Refresh (Performance Optimized)**
```
User: Smart refresh on frequently-used repository
Enhanced System:
1. âœ… Only clears wiki cache (existing)
2. ğŸ†• Reuses BAML classification cache (fast)
3. ğŸ†• Only updates changed Graphiti relationships
4. ğŸ†• Result: <30s refresh vs. >2min full rebuild
```

---

## ğŸš€ **Getting Started**

### **Next Actions (Week 1)**
1. **Install BAML**: `pip install baml-py` and setup in api/ directory
2. **Create Basic Schema**: Start with classification.baml for intent detection
3. **Test with Existing Query**: Use your SQL error example for DEBUGGING_HELP classification
4. **Create Enhanced RAG**: Extend existing api/rag.py with BAML classification
5. **Validate WebSocket**: Test enhanced features through /ws/chat interface
6. **Performance Check**: Ensure <500ms classification overhead

### **Success Criteria for Phase 1**
- âœ… **Zero Breaking Changes**: All existing functionality works unchanged
- âœ… **BAML Classification**: 80%+ accuracy on BUILD_GUIDANCE vs DEBUGGING_HELP
- âœ… **WebSocket Integration**: External agents receive structured responses
- âœ… **Performance**: Classification adds <500ms latency
- âœ… **Fallback Works**: System gracefully falls back to existing pipeline on errors

### **Success Criteria for Complete Implementation**
- âœ… **Cross-Repository Analysis**: coding-agent â†” hekmatica relationships detected
- âœ… **Enhanced Build Guidance**: Step-by-step guides with dependencies
- âœ… **External Agent Value**: Your coding-agent gets actionable structured responses
- âœ… **Production Ready**: <3s response time for complex cross-repo queries
- âœ… **Backward Compatible**: All existing interfaces and features preserved
- âœ… **Smart Refresh**: Intelligent cache invalidation preserves performance

---

## ğŸ‰ **Expected Impact**

### **For Your External Agents (Immediate)**
- ğŸ¤– **Structured WebSocket Responses**: Type-safe, actionable guidance instead of free-form text
- ğŸ—ï¸ **Cross-Repository Intelligence**: Your coding-agent can learn from hekmatica patterns
- ğŸ“‹ **Step-by-Step Build Guides**: Structured responses with dependencies and examples
- ğŸ”§ **Enhanced Debugging**: BAML classification routes error queries to relevant solutions

### **For DeepWiki Platform (Strategic)**
- ğŸš€ **Multi-Interface Intelligence**: Enhance Web UI, WebSocket, HTTP, and Export APIs
- ğŸ“Š **Advanced Analytics**: Understand query patterns and repository relationships
- ğŸ”„ **Intelligent Caching**: Pre-compute architectural guidance for common patterns
- ğŸŒ **Ecosystem Understanding**: Map technology relationships across all processed repositories

### **Real-World Example**
```
Before: "How do I build a Docker-based agent?"
â†’ Raw text response with Docker code snippets

After: Your coding-agent receives:
{
  "intent": "BUILD_GUIDANCE",
  "build_steps": [
    {
      "step_number": 1,
      "title": "Setup Agent Core",
      "dependencies": ["AdalFlow", "TaskHandler"],
      "code_examples": [{
        "repository": "coding-agent",
        "file_path": "src/core/agent.py",
        "explanation": "Core agent initialization with state management"
      }]
    }
  ],
  "related_repositories": ["hekmatica", "develop-with-aristops"],
  "confidence_score": 0.92
}
```

---

*This enhancement preserves all existing functionality while adding intelligence that transforms DeepWiki from a code search tool into an architectural guidance platform for multi-repository development.*

---

## ğŸ” **Comprehensive Integration Analysis**

### **âœ… What We've Covered So Far**
- Enhanced RAG pipeline with BAML classification
- Cross-repository analysis with Graphiti
- Backward-compatible refresh system
- Basic BAML schemas and response structuring

### **ğŸš¨ Critical Integration Points We Must Address**

#### **1. Configuration Management System**
```python
# Current: api/config.py loads JSON configs with env substitution
# NEW: Need to add BAML and Graphiti configurations

# Required New Config Files:
api/config/baml.json       # BAML model settings and API keys
api/config/graphiti.json   # Graph database connection and settings

# Enhanced config loading in api/config.py:
def load_baml_config():
    return load_json_config("baml.json")

def load_graphiti_config():
    return load_json_config("graphiti.json")
```

#### **2. Environment Variables**
```bash
# NEW environment variables needed:
BAML_API_KEY=your_baml_api_key               # If using hosted BAML
GRAPHITI_DATABASE_URL=neo4j://localhost:7687 # Graph database connection
GRAPHITI_USERNAME=neo4j                      # Graph DB credentials
GRAPHITI_PASSWORD=your_password              # Graph DB credentials
FALKORDB_URL=redis://localhost:6379          # Alternative: FalkorDB

# Update .env template in documentation
# Update Docker environment handling
# Update all README files in 9 languages
```

#### **3. Dependencies & Requirements**
```python
# api/requirements.txt additions:
baml-py>=0.1.0                    # BAML Python client
graphiti-core>=0.1.0              # Graphiti knowledge graph
neo4j>=5.0.0                      # Neo4j driver (if using Neo4j)
falkordb>=1.0.0                   # FalkorDB driver (alternative)

# pyproject.toml updates needed
# package.json might need TypeScript BAML client
```

#### **4. Pydantic Data Models**
```python
# Current models in api/api.py need enhancement:

class EnhancedChatCompletionRequest(ChatCompletionRequest):
    # Add new optional fields
    enable_baml_classification: Optional[bool] = Field(True, description="Enable BAML query classification")
    enable_cross_repo_analysis: Optional[bool] = Field(True, description="Enable Graphiti cross-repository search")
    response_format: Optional[str] = Field("markdown", description="Response format: markdown, structured, json")

class RepositoryAnalysis(BaseModel):
    """New model for BAML repository analysis results"""
    repository_url: str
    technologies: List[str]
    architecture_patterns: List[str]
    complexity_score: float
    main_components: List[str]

class CrossRepoRelationship(BaseModel):
    """New model for Graphiti relationships"""
    source_repo: str
    target_repo: str
    relationship_type: str
    strength: float
    explanation: str
```

#### **5. WebSocket Message Format Updates**
```typescript
// src/utils/websocketClient.ts enhancements needed:

export interface EnhancedChatCompletionRequest extends ChatCompletionRequest {
  enable_baml_classification?: boolean;
  enable_cross_repo_analysis?: boolean;
  response_format?: "markdown" | "structured" | "json";
}

export interface StructuredResponse {
  intent: string;
  summary: string;
  build_steps?: BuildStep[];
  architecture_overview?: string;
  related_repositories?: string[];
  confidence_score: number;
}

// Need to handle structured responses in WebSocket client
```

#### **6. Error Handling Patterns**
```python
# Current pattern in api/websocket_wiki.py - need to extend:

try:
    # Enhanced RAG processing
    baml_result = await enhanced_rag.classify_query(query)
    graphiti_result = await enhanced_rag.cross_repo_analysis(query)
except BAMLServiceError as e:
    logger.error(f"BAML classification failed: {str(e)}")
    # Fallback to existing pipeline
    await websocket.send_text("Warning: Using fallback analysis due to classification service unavailability")
except GraphitiConnectionError as e:
    logger.error(f"Graphiti connection failed: {str(e)}")
    # Continue with single-repo analysis
    await websocket.send_text("Note: Cross-repository analysis unavailable, using single-repository mode")
```

#### **7. Logging Configuration**
```python
# api/logging_config.py needs updates:

# New loggers for BAML and Graphiti
logging.getLogger("baml").setLevel(log_level)
logging.getLogger("graphiti").setLevel(log_level)

# New log categories
logger.info("BAML classification completed", extra={"component": "baml", "query_intent": intent})
logger.info("Graphiti relationships mapped", extra={"component": "graphiti", "repo_count": count})
```

#### **8. Cache Structure Extensions**
```python
# Current cache paths need expansion:
~/.adalflow/repos/           # Existing: Repository files
~/.adalflow/databases/       # Existing: FAISS embeddings  
~/.adalflow/wikicache/      # Existing: Generated wiki content

# NEW cache directories needed:
~/.adalflow/baml_cache/      # BAML classification cache
~/.adalflow/graphiti_data/   # Graphiti graph database files
~/.adalflow/repo_analysis/   # Repository analysis results

# Update cache management in api/api.py
def get_enhanced_cache_paths():
    base = get_adalflow_default_root_path()
    return {
        "baml_cache": os.path.join(base, "baml_cache"),
        "graphiti_data": os.path.join(base, "graphiti_data"),
        "repo_analysis": os.path.join(base, "repo_analysis")
    }
```

#### **9. Docker Configuration Updates**
```dockerfile
# Dockerfile needs additional dependencies:
RUN apt-get update && apt-get install -y \
    curl \
    gnupg \
    git \
    ca-certificates \
    # NEW: Neo4j/Graph database tools
    default-jre \  
    && rm -rf /var/lib/apt/lists/*

# docker-compose.yml needs new services:
services:
  deepwiki:
    # existing config
    depends_on:
      - neo4j  # or falkordb
  
  neo4j:
    image: neo4j:5.0
    environment:
      - NEO4J_AUTH=neo4j/password
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
```

#### **10. API Response Format Enhancements**
```python
# Export functionality needs updates for structured responses
# api/api.py export endpoints:

@app.get("/export/wiki/{owner}/{repo}")
async def export_wiki_enhanced(
    owner: str, 
    repo: str,
    format: str = "markdown",
    include_relationships: bool = False,  # NEW
    include_analysis: bool = False        # NEW
):
    # Enhanced export with BAML analysis and Graphiti relationships
```

#### **11. Multi-language Support (i18n)**
```json
// ALL 9 language files need updates:
// src/messages/en.json, es.json, fr.json, ja.json, kr.json, pt-br.json, vi.json, zh-tw.json, zh.json

{
  "enhanced": {
    "bamlClassification": "Query Classification",
    "crossRepoAnalysis": "Cross-Repository Analysis", 
    "structuredResponse": "Structured Response",
    "intelligentRefresh": "Intelligent Refresh",
    "relationshipMapping": "Relationship Mapping"
  }
}
```

#### **12. Performance & Memory Considerations**
```python
# Enhanced memory management needed:
# Current: 6GB limit in docker-compose.yml
# NEW: May need 8GB+ for graph processing

# Resource monitoring for:
# - BAML classification overhead (<500ms target)
# - Graphiti query performance (<3s target)  
# - Memory usage for large graphs
# - Concurrent WebSocket connections with enhanced features
```

#### **13. Health Check Enhancements**
```python
# api/api.py needs enhanced health checks:

@app.get("/health")
async def enhanced_health_check():
    return {
        "status": "healthy",
        "components": {
            "faiss": await check_faiss_health(),
            "baml": await check_baml_health(),      # NEW
            "graphiti": await check_graphiti_health() # NEW
        }
    }
```

#### **14. Authentication & Authorization**
```python
# Current: DEEPWIKI_AUTH_MODE and DEEPWIKI_AUTH_CODE
# NEW: May need separate auth for enhanced features

DEEPWIKI_ENHANCED_FEATURES_AUTH=true     # Control access to BAML/Graphiti
DEEPWIKI_CROSS_REPO_AUTH=admin_only      # Restrict cross-repo analysis
```

#### **15. Database Migration Strategy**
```python
# Need migration scripts for existing data:
# api/migration/
#   â”œâ”€â”€ migrate_existing_repos.py      # Analyze existing repos with BAML
#   â”œâ”€â”€ build_initial_graph.py         # Create Graphiti relationships
#   â””â”€â”€ cache_classification.py        # Pre-populate BAML cache
```

---

## ğŸ¯ **Updated Implementation Priority**

### **Phase 1: Infrastructure (Week 1)**
1. âœ… **Configuration system** - Add BAML/Graphiti configs
2. âœ… **Dependencies** - Update requirements and Docker
3. âœ… **Environment setup** - New env vars and validation
4. âœ… **Health checks** - Enhanced monitoring
5. âœ… **Error handling** - Extend existing patterns

### **Phase 2: Core Integration (Week 2-3)**
1. âœ… **Data models** - Extend Pydantic schemas
2. âœ… **WebSocket enhancements** - Structured response support
3. âœ… **Cache management** - New cache directories and logic
4. âœ… **Enhanced RAG** - BAML + Graphiti integration
5. âœ… **Migration scripts** - Existing data transformation

### **Phase 3: Production Ready (Week 4)**
1. âœ… **Performance optimization** - Memory and query tuning
2. âœ… **Multi-language support** - Update all i18n files
3. âœ… **Export enhancements** - Structured data export
4. âœ… **Documentation updates** - All README files in 9 languages
5. âœ… **Integration testing** - Full system validation

**Total Scope: ~60 files need updates across the entire system** 